{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.firefox.firefox_binary import FirefoxBinary\n",
    "import time\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "url  = 'https://www.goodreads.com/list/show/55.Disappointing_Books?page='\n",
    "link = 'https://www.goodreads.com/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary = FirefoxBinary('C:/Program Files/Mozilla Firefox/firefox.exe')\n",
    "driver = webdriver.Firefox(firefox_binary=binary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def scroll_shim(passed_in_driver, object):\n",
    "        x = object.location['x']\n",
    "        y = object.location['y']\n",
    "        scroll_by_coord = 'window.scrollTo(%s,%s);' % (\n",
    "            x,\n",
    "            y\n",
    "        )\n",
    "        scroll_nav_out_of_way = 'window.scrollBy(0, -120);'\n",
    "        passed_in_driver.execute_script(scroll_by_coord)\n",
    "        passed_in_driver.execute_script(scroll_nav_out_of_way)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5,7):\n",
    "    url  = 'https://www.goodreads.com/list/show/55.Disappointing_Books?page='\n",
    "    url     = url +str(i)\n",
    "    soup    = BeautifulSoup(requests.get(url).text,features=\"lxml\")\n",
    "    request = requests.get(url)\n",
    "    \n",
    "    BeautifulSoup(request.text, 'html.parser')  \n",
    "    for a in soup.select('a[class=\"bookTitle\"]'):\n",
    "        \n",
    "        url  = link+a['href']\n",
    "        print(url)\n",
    "        \n",
    "        soup = BeautifulSoup(requests.get(url).text,features=\"lxml\")\n",
    "        soup.findAll(\"body\")\n",
    "\n",
    "        request  =  requests.get(url)\n",
    "        BeautifulSoup(request.text, 'html.parser')\n",
    "                \n",
    "\n",
    "        Title   = soup.select('h1[id=\"bookTitle\"]')\n",
    "        Title   = [re.sub(r'<.+?>',r'',str(a)) for a in Title]\n",
    "        Title   = [re.sub(r'\\n',r'',str(a)) for a in Title]\n",
    "        b = \"!@/;+-*()[]_{}:#$',\\#?éà@\\\"\"\n",
    "        Title   = str(Title)\n",
    "        for char in b:\n",
    "            Title = Title.replace(char,\"\")      \n",
    "        Title     = str(Title).translate({ord(i): None for i in \"[':]\"})\n",
    "        Title     = Title.strip(':')\n",
    "        \n",
    "        Comments  = soup.select('span[id^=\"reviewTextContainer\"]')\n",
    "        Comments  = [re.sub(r'<.+?>',r'',str(a)) for a in Comments]\n",
    "        Comments  = [re.sub(r'\\n',r'',str(a)) for a in Comments]\n",
    "        \n",
    "        #Driver\n",
    "        driver.get(url) \n",
    "        html = driver.page_source\n",
    "        \n",
    "        time.sleep(2)\n",
    "        liste = []\n",
    "        for i in range(1,5):\n",
    "            element = driver.find_element_by_xpath(\"//*[@id='reviews']/div[5]/div/a[\"+str(i)+\"]\")\n",
    "            \n",
    "            time.sleep(3)\n",
    "            if 'firefox' in driver.capabilities['browserName']:\n",
    "                scroll_shim(driver, element)\n",
    "            actions = ActionChains(driver)\n",
    "            actions.move_to_element(element)\n",
    "            actions.click()\n",
    "            actions.perform()\n",
    "            time.sleep(10)\n",
    "            all_comments  =  driver.find_elements_by_xpath(\"//*[contains(@id,'freeTextContainer')]\")\n",
    "            \n",
    "            for c in all_comments:\n",
    "                time.sleep(2)\n",
    "                liste.insert(len(liste),c.text)\n",
    "                print(len(liste))\n",
    "                driver.refresh\n",
    "            time.sleep(2)\n",
    "            \n",
    "        liste          = pd.DataFrame(liste)\n",
    "        df_Comments    = pd.DataFrame(Comments)\n",
    "        #final_result   = pd.concat([df_Comments,liste])\n",
    "        \n",
    "        df        = pd.DataFrame(liste)\n",
    "        df2       = pd.DataFrame(df_Comments)\n",
    "        frames    = [df2,df]\n",
    "        result    = pd.concat(frames)\n",
    "        result.rename(columns={ df.columns[0]: \"Comments\" })\n",
    "        result.to_csv('E:/BD2C/Semestre III/Text minning/Projet/Dataset2/'+str(Title)+'.csv', header=['Comments']   , index=None, sep=' ', mode='a')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
